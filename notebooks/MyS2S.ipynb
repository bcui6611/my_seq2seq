{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.layers.core import Dense\n",
    "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors\n",
    "import tensorflow.contrib.seq2seq.python.ops.attention_wrapper\n",
    "import tensorflow.contrib.seq2seq.python.ops.beam_search_decoder\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi What is your name?\n",
      "([16, 6, 7, 9, 39, 5, 1, 1, 1, 1], 6)\n",
      "Hi this is Jaemin.\n",
      "([0, 16, 41, 7, 36, 3, 2, 1, 1, 1, 1], 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'_GO_ Hi this is Jaemin . _END_ _PAD_ _PAD_ _PAD_ _PAD_'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pprint\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# maximum length of input and target sentences including paddings\n",
    "enc_sentence_length = 10\n",
    "dec_sentence_length = 10\n",
    "\n",
    "# Batch_size: 2\n",
    "input_batches = [\n",
    "    ['Hi What is your name?', 'Nice to meet you!'],\n",
    "    ['Which programming language do you use?', 'See you later.'],\n",
    "    ['Where do you live?', 'What is your major?'],\n",
    "    ['What do you want to drink?', 'What is your favorite beer?']]\n",
    "\n",
    "target_batches = [\n",
    "    ['Hi this is Jaemin.', 'Nice to meet you too!'],\n",
    "    ['I like Python.', 'Bye Bye.'],\n",
    "    ['I live in Seoul, South Korea.', 'I study industrial engineering.'],\n",
    "    ['Beer please!', 'Leffe brown!']]\n",
    "\n",
    "all_input_sentences = []\n",
    "for input_batch in input_batches:\n",
    "    all_input_sentences.extend(input_batch)\n",
    "    \n",
    "all_target_sentences = []\n",
    "for target_batch in target_batches:\n",
    "    all_target_sentences.extend(target_batch)\n",
    "    \n",
    "def tokenizer(sentence):\n",
    "    tokens = re.findall(r\"[\\w]+|[^\\s\\w]\", sentence)\n",
    "    return tokens\n",
    "\n",
    "_START_ = \"_GO_\"\n",
    "_PAD_ = \"_PAD_\"\n",
    "_END_ = \"_END_\"\n",
    "\n",
    "def build_vocab(sentences, max_vocab_size=None):\n",
    "    word_counter = Counter()\n",
    "    vocab = dict()\n",
    "    reverse_vocab = dict()\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        tokens = tokenizer(sentence)\n",
    "        word_counter.update(tokens)\n",
    "        \n",
    "    if max_vocab_size is None:\n",
    "        max_vocab_size = len(word_counter)\n",
    "    \n",
    "    vocab[_START_] = 0\n",
    "    vocab[_PAD_] = 1\n",
    "    vocab[_END_] = 2\n",
    "    vocab_idx = 3\n",
    "    for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "            \n",
    "    for key, value in vocab.items():\n",
    "        reverse_vocab[value] = key\n",
    "            \n",
    "    return vocab, reverse_vocab, max_vocab_size\n",
    "\n",
    "vocab,reverse_vocab,max_vocab_size = build_vocab(all_input_sentences+all_target_sentences)\n",
    "\n",
    "def token2idx(word, vocab):\n",
    "    return vocab[word]\n",
    "\n",
    "def sent2idx(sent, vocab=vocab, max_sentence_length=enc_sentence_length, is_target=False):\n",
    "    tokens = tokenizer(sent)\n",
    "    current_length = len(tokens)\n",
    "    pad_length = max_sentence_length - current_length\n",
    "    if is_target:\n",
    "        return [0] + [token2idx(token, vocab) for token in tokens] + [2] + [1] * (pad_length-1), current_length + 1\n",
    "    else:\n",
    "        return [token2idx(token, vocab) for token in tokens] + [1] * pad_length, current_length\n",
    "\n",
    "def idx2token(idx, reverse_vocab):\n",
    "    return reverse_vocab[idx]\n",
    "\n",
    "def idx2sent(indices, reverse_vocab=reverse_vocab):\n",
    "    return \" \".join([idx2token(idx, reverse_vocab) for idx in indices])\n",
    "\n",
    "# Enc Example\n",
    "print('Hi What is your name?')\n",
    "print(sent2idx('Hi What is your name?'))\n",
    "\n",
    "# Dec Example\n",
    "print('Hi this is Jaemin.')\n",
    "print(sent2idx('Hi this is Jaemin.', max_sentence_length=dec_sentence_length, is_target=True))\n",
    "\n",
    "idx2sent([0, 16, 41, 7, 36, 3, 2, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-7116aa00658a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m                            \u001b[0mvocab_lower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_upper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                            batch_size=2)\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not callable"
     ]
    }
   ],
   "source": [
    "def batch(inputs, max_sequence_length=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        inputs:\n",
    "            list of sentences (integer lists)\n",
    "        max_sequence_length:\n",
    "            integer specifying how large should `max_time` dimension be.\n",
    "            If None, maximum sequence length would be used\n",
    "    \n",
    "    Outputs:\n",
    "        inputs_time_major:\n",
    "            input sentences transformed into time-major matrix \n",
    "            (shape [max_time, batch_size]) padded with 0s\n",
    "        sequence_lengths:\n",
    "            batch-sized list of integers specifying amount of active \n",
    "            time steps in each input sequence\n",
    "    \"\"\"\n",
    "    \n",
    "    sequence_lengths = [len(seq) for seq in inputs]\n",
    "    batch_size = len(inputs)\n",
    "    \n",
    "    if max_sequence_length is None:\n",
    "        max_sequence_length = max(sequence_lengths)\n",
    "    \n",
    "    inputs_batch_major = np.zeros(shape=[batch_size, max_sequence_length], dtype=np.int32) # == PAD\n",
    "    \n",
    "    for i, seq in enumerate(inputs):\n",
    "        for j, element in enumerate(seq):\n",
    "            inputs_batch_major[i, j] = element\n",
    "\n",
    "    # [batch_size, max_time] -> [max_time, batch_size]\n",
    "    inputs_time_major = inputs_batch_major.swapaxes(0, 1)\n",
    "\n",
    "    #return inputs_time_major, sequence_lengths\n",
    "    return inputs_batch_major, sequence_lengths\n",
    "\n",
    "\n",
    "def random_sequences(length_from, length_to,\n",
    "                     vocab_lower, vocab_upper,\n",
    "                     batch_size):\n",
    "    \"\"\" Generates batches of random integer sequences,\n",
    "        sequence length in [length_from, length_to],\n",
    "        vocabulary in [vocab_lower, vocab_upper]\n",
    "    \"\"\"\n",
    "    if length_from > length_to:\n",
    "            raise ValueError('length_from > length_to')\n",
    "\n",
    "    def random_length():\n",
    "        if length_from == length_to:\n",
    "            return length_from\n",
    "        return np.random.randint(length_from, length_to + 1)\n",
    "    \n",
    "    while True:\n",
    "        yield [\n",
    "            np.random.randint(low=vocab_lower,\n",
    "                              high=vocab_upper,\n",
    "                              size=random_length()).tolist()\n",
    "            for _ in range(batch_size)\n",
    "        ]\n",
    "        \n",
    "batches = random_sequences(length_from=5, length_to=20,\n",
    "                           vocab_lower=2, vocab_upper=15,\n",
    "                           batch_size=2)\n",
    "loss_track = []\n",
    "try:\n",
    "    for batch in range(max_batches+1):\n",
    "        batch_data = next(batches)\n",
    "            fd = model.make_train_inputs(batch_data, batch_data)\n",
    "            _, l = session.run([model.train_op, model.loss], fd)\n",
    "            loss_track.append(l)\n",
    "\n",
    "            if verbose:\n",
    "                if batch == 0 or batch % batches_in_epoch == 0:\n",
    "                    print('batch {}'.format(batch))\n",
    "                    print('  minibatch loss: {}'.format(session.run(model.loss, fd)))\n",
    "                    for i, (e_in, dt_pred) in enumerate(zip(\n",
    "                            fd[model.encoder_inputs].T,\n",
    "                            session.run(model.decoder_prediction_train, fd).T\n",
    "                        )):\n",
    "                        print('  sample {}:'.format(i + 1))\n",
    "                        print('    enc input           > {}'.format(e_in))\n",
    "                        print('    dec train predicted > {}'.format(dt_pred))\n",
    "                        if i >= 2:\n",
    "                            break\n",
    "                    print()\n",
    "    except KeyboardInterrupt:\n",
    "        print('training interrupted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(opt):\n",
    "    if opt == \"adam\":\n",
    "        optfn = tf.train.AdamOptimizer\n",
    "    elif opt == \"sgd\":\n",
    "        optfn = tf.train.GradientDescentOptimizer\n",
    "    else:\n",
    "        assert(False)\n",
    "    return optfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_rnn_cell(cell_name,dim_size, train_phase = True, keep_prob = 0.75):\n",
    "    if cell_name == \"gru\":\n",
    "        cell = tf.contrib.rnn.GRUCell(dim_size)\n",
    "    elif cell_name == \"lstm\":\n",
    "        cell = tf.contrib.rnn.LSTMCell(dim_size)\n",
    "    else:\n",
    "        cell = tf.contrib.rnn.BasicRNNCell(dim_size)\n",
    "    if train_phase and keep_prob < 1.0:\n",
    "        cell = tf.contrib.rnn.DropoutWrapper(\n",
    "              cell=cell,\n",
    "              input_keep_prob=keep_prob,\n",
    "              output_keep_prob=keep_prob)\n",
    "    return cell\n",
    "\n",
    "def multi_rnn_cell(cell_name,dim_size,num_layers = 1, train_phase = True, keep_prob=0.75):\n",
    "    cells = []\n",
    "    for _ in range(num_layers):\n",
    "        cell = single_rnn_cell(cell_name,dim_size, train_phase, keep_prob)\n",
    "        cells.append(cell)\n",
    "    \n",
    "    if len(cells) > 1:\n",
    "        final_cell = tf.contrib.rnn.MultiRNNCell(cells=cells)\n",
    "    else:\n",
    "        final_cell = cells[0]\n",
    "    return final_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicS2SModel(object):\n",
    "    def __init__(self, vocab, batch_size = 2, dim_size=128, rnn_cell = 'gru', num_layers=2, max_gradient_norm=5.0, atten_size=30, \n",
    "                 learning_rate=0.001, learning_rate_decay_factor=0.98, dropout=0.2,max_inference_lenght=10,\n",
    "                 max_source_len = 10, max_target_len = 10,beam_size =3, optimizer=\"adam\", mode ='train',\n",
    "                 use_beam_search = False):\n",
    "        assert mode in ['train', 'inference']\n",
    "        self.start_token = vocab.get(_START_)\n",
    "        self.end_token = vocab.get(_END_)\n",
    "        self.train_phase = True if mode == 'train' else False\n",
    "        self.cell_name = rnn_cell\n",
    "        self.dim_size = dim_size\n",
    "        self.vocab_size = len(vocab)\n",
    "        self.num_layers = num_layers\n",
    "        self.keep_prob_config = 1.0 - dropout\n",
    "        self.atten_size = atten_size\n",
    "        \n",
    "        # decoder\n",
    "        self.max_inference_lenght = max_inference_lenght\n",
    "        \n",
    "        # beam search\n",
    "        self.beam_size = beam_size\n",
    "        self.beam_search = use_beam_search\n",
    "        \n",
    "        # learning\n",
    "        self.learning_rate = tf.Variable(float(learning_rate), trainable=False)\n",
    "        self.learning_rate_decay_op = self.learning_rate.assign(self.learning_rate * learning_rate_decay_factor)\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        \n",
    "        # if we use beam search decoder, we need to specify the batch size and max source len\n",
    "        if self.beam_search:\n",
    "            self.batch_size = batch_size\n",
    "            self.source_tokens = tf.placeholder(tf.int32, shape=[batch_size, max_source_len])\n",
    "            self.source_length = tf.placeholder(tf.int32, shape=[batch_size,])\n",
    "        else:\n",
    "            self.source_tokens = tf.placeholder(tf.int32,shape=[None,None])\n",
    "            self.source_length = tf.placeholder(tf.int32,shape=[None,])\n",
    "            \n",
    "        if self.train_phase:\n",
    "            self.target_tokens = tf.placeholder(tf.int32, shape=[None, None])\n",
    "            self.target_length = tf.placeholder(tf.int32, shape=[None,])\n",
    "         \n",
    "        with tf.variable_scope(\"S2S\",initializer = tf.uniform_unit_scaling_initializer(1.0)):\n",
    "            self.setup_embeddings()\n",
    "            #self.setup_encoder()\n",
    "            self.setup_bidirection_encoder()\n",
    "            self.setup_attention_decoder()\n",
    "                \n",
    "        if self.train_phase:\n",
    "            opt = get_optimizer(optimizer)(self.learning_rate)\n",
    "            params = tf.trainable_variables()\n",
    "            gradients = tf.gradients(self.losses, params)\n",
    "            clipped_gradients, _ = tf.clip_by_global_norm(gradients, max_gradient_norm)\n",
    "            self.gradient_norm = tf.global_norm(gradients)\n",
    "            self.param_norm = tf.global_norm(params)\n",
    "            self.updates = opt.apply_gradients(zip(clipped_gradients, params), global_step=self.global_step)\n",
    "    \n",
    "    def setup_embeddings(self):\n",
    "        with tf.variable_scope(\"Embeddings\"):\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.enc_emd = tf.get_variable(\"encode_embedding\", [self.vocab_size, self.dim_size])\n",
    "                self.dec_emd = tf.get_variable(\"decode_embedding\", [self.vocab_size, self.dim_size])\n",
    "                self.encoder_inputs = tf.nn.embedding_lookup(self.enc_emd, self.source_tokens)\n",
    "                if self.train_phase:\n",
    "                    self.decoder_inputs = tf.nn.embedding_lookup(self.dec_emd, self.target_tokens)\n",
    "    \n",
    "    def setup_encoder(self):\n",
    "        cell = multi_rnn_cell(self.cell_name,self.dim_size, self.num_layers, self.train_phase,self.keep_prob_config)\n",
    "        outputs,state = tf.nn.dynamic_rnn(cell,inputs=self.encoder_inputs,sequence_length=self.source_length,dtype=tf.float32)\n",
    "        self.encode_output = outputs\n",
    "        self.encode_state = state\n",
    "        # using the state of last layer of rnn as initial state\n",
    "        self.decode_initial_state = self.encode_state[-1]\n",
    "        \n",
    "    def setup_bidirection_encoder(self):\n",
    "        fw_cell = single_rnn_cell('gru',self.dim_size, train_phase=self.train_phase, keep_prob=self.keep_prob_config)\n",
    "        bw_cell = single_rnn_cell('gru',self.dim_size, train_phase=self.train_phase, keep_prob=self.keep_prob_config)\n",
    "        \n",
    "        with tf.variable_scope(\"Encoder\"):\n",
    "            outputs,states = tf.nn.bidirectional_dynamic_rnn(\n",
    "                cell_fw = fw_cell,\n",
    "                cell_bw = bw_cell,\n",
    "                dtype = tf.float32,\n",
    "                sequence_length = self.source_length,\n",
    "                inputs = self.encoder_inputs\n",
    "                )\n",
    "            outputs_concat = tf.concat(outputs, 2)\n",
    "        self.encode_output = outputs_concat\n",
    "        self.encode_state = states\n",
    "        \n",
    "        # use Dense layer to convert bi-direction state to decoder inital state\n",
    "        convert_layer = Dense(self.dim_size,dtype=tf.float32,name=\"bi_convert\")\n",
    "        self.decode_initial_state = convert_layer(tf.concat(self.encode_state,axis=1))\n",
    "        \n",
    "    def setup_training_decoder_layer(self):\n",
    "        max_dec_len = tf.reduce_max(self.target_length, name='max_dec_len')\n",
    "        training_helper = tf.contrib.seq2seq.TrainingHelper(self.decoder_inputs,self.target_length,name=\"training_helper\")\n",
    "        training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "            cell = self.dec_cell,\n",
    "            helper = training_helper,\n",
    "            initial_state = self.initial_state,\n",
    "            output_layer = self.output_layer\n",
    "        )\n",
    "        train_dec_outputs, train_dec_last_state,_ = tf.contrib.seq2seq.dynamic_decode(\n",
    "            training_decoder,\n",
    "            output_time_major=False,\n",
    "            impute_finished=True,\n",
    "            maximum_iterations=max_dec_len)\n",
    "        \n",
    "        # logits: [batch_size x max_dec_len x vocab_size]\n",
    "        logits = tf.identity(train_dec_outputs.rnn_output, name='logits')\n",
    "\n",
    "        # targets: [batch_size x max_dec_len x vocab_size]\n",
    "        targets = tf.slice(self.target_tokens, [0, 0], [-1, max_dec_len], 'targets')\n",
    "\n",
    "        masks = tf.sequence_mask(self.target_length,max_dec_len,dtype=tf.float32,name=\"mask\")\n",
    "        self.losses = tf.contrib.seq2seq.sequence_loss(logits=logits,targets=targets,weights=masks,name=\"losses\")\n",
    "        \n",
    "        # prediction sample for validation\n",
    "        self.valid_predictions = tf.identity(train_dec_outputs.sample_id, name='valid_preds')\n",
    "    \n",
    "    def setup_inference_decoder_layer(self):\n",
    "        start_tokens = tf.tile(tf.constant([self.start_token],dtype=tf.int32),[self.batch_size])\n",
    "        inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "            embedding=self.dec_emd,\n",
    "            start_tokens=start_tokens,\n",
    "            end_token=self.end_token)\n",
    "        \n",
    "        inference_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "            cell = self.dec_cell,\n",
    "            helper = inference_helper, \n",
    "            initial_state=self.initial_state,\n",
    "            output_layer=self.output_layer)\n",
    "        \n",
    "        infer_dec_outputs, infer_dec_last_state,_ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    inference_decoder,\n",
    "                    output_time_major=False,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=self.max_inference_lenght)\n",
    "        # [batch_size x dec_sentence_length], tf.int32\n",
    "        self.predictions = tf.identity(infer_dec_outputs.sample_id, name='predictions')\n",
    "            \n",
    "    def setup_beam_search_decoder_layer(self):\n",
    "        start_tokens = tf.tile(tf.constant([self.start_token],dtype=tf.int32),[self.batch_size])\n",
    "        bsd = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "                    cell=self.dec_cell,\n",
    "                    embedding=self.dec_emd,\n",
    "                    start_tokens= start_tokens,\n",
    "                    end_token=self.end_token,\n",
    "                    initial_state=self.initial_state,\n",
    "                    beam_width=self.beam_size,\n",
    "                    output_layer=self.output_layer,\n",
    "                    length_penalty_weight=0.0)\n",
    "        # final_outputs are instances of FinalBeamSearchDecoderOutput\n",
    "        final_outputs, final_state, final_sequence_lengths = tf.contrib.seq2seq.dynamic_decode(\n",
    "            bsd, \n",
    "            output_time_major=False,\n",
    "           # impute_finished=True,\n",
    "            maximum_iterations=self.max_inference_lenght\n",
    "        )\n",
    "        beam_predictions = final_outputs.predicted_ids\n",
    "        self.beam_predictions = tf.transpose(beam_predictions,perm=[0,2,1])\n",
    "        self.beam_prob = final_outputs.beam_search_decoder_output.scores\n",
    "        self.beam_ids = final_outputs.beam_search_decoder_output.predicted_ids\n",
    "        \n",
    "    def setup_attention_decoder(self):\n",
    "        #dec_cell = multi_rnn_cell('gru',self.dim_size,num_layers=self.num_layers, train_phase = self.train_phase, keep_prob=self.keep_prob_config)\n",
    "        dec_cell = [single_rnn_cell(self.cell_name,self.dim_size,self.train_phase,self.keep_prob_config) for i in range(self.num_layers)]\n",
    "        if self.beam_search:\n",
    "            memory = tf.contrib.seq2seq.tile_batch(self.encode_output,multiplier = self.beam_size)\n",
    "            memory_sequence_length = tf.contrib.seq2seq.tile_batch(self.source_length,multiplier = self.beam_size)\n",
    "        else:\n",
    "            memory = self.encode_output\n",
    "            memory_sequence_length = self.source_length\n",
    "            \n",
    "        attn_mech = tf.contrib.seq2seq.BahdanauAttention(\n",
    "            num_units = self.atten_size,\n",
    "            memory = memory,\n",
    "            memory_sequence_length = memory_sequence_length,\n",
    "            name = \"BahdanauAttention\"\n",
    "        )\n",
    "        dec_cell[0] = tf.contrib.seq2seq.AttentionWrapper(\n",
    "            cell=dec_cell[0],\n",
    "            attention_mechanism=attn_mech,\n",
    "            attention_layer_size=self.atten_size)\n",
    "        \n",
    "        if self.beam_search:\n",
    "            tile_state = tf.contrib.seq2seq.tile_batch(self.decode_initial_state,self.beam_size)\n",
    "            initial_state = [tile_state for i in range(self.num_layers)]\n",
    "            cell_state = dec_cell[0].zero_state(dtype=tf.float32,batch_size=self.batch_size*self.beam_size)\n",
    "            initial_state[0] = cell_state.clone(cell_state=initial_state[0])\n",
    "            self.initial_state = tuple(initial_state)\n",
    "        else:\n",
    "            # we use dynamic batch size\n",
    "            self.batch_size = tf.shape(self.encoder_inputs)[0]\n",
    "            initial_state = [self.decode_initial_state for i in range(self.num_layers)]\n",
    "            cell_state = dec_cell[0].zero_state(dtype=tf.float32, batch_size = self.batch_size)\n",
    "            initial_state[0] = cell_state.clone(cell_state=initial_state[0])\n",
    "            self.initial_state = tuple(initial_state)\n",
    "            \n",
    "        print(self.initial_state)\n",
    "        self.dec_cell = tf.contrib.rnn.MultiRNNCell(dec_cell)\n",
    "        self.output_layer = Dense(self.vocab_size,kernel_initializer = tf.truncated_normal_initializer(mean = 0.0, stddev=0.1))\n",
    "        if self.train_phase:\n",
    "            self.setup_training_decoder_layer()\n",
    "        else:\n",
    "            if self.beam_search:\n",
    "                self.setup_beam_search_decoder_layer()\n",
    "            else:\n",
    "                self.setup_inference_decoder_layer()\n",
    "    \n",
    "    def train_one_step(self,sess,encode_input,encode_len,decode_input,decode_len):\n",
    "        feed_dict = {}\n",
    "        feed_dict[self.source_tokens] = encode_input\n",
    "        feed_dict[self.source_length] = encode_len\n",
    "        feed_dict[self.target_tokens] = decode_input\n",
    "        feed_dict[self.target_length] = decode_len\n",
    "        valid_predictions,loss,_ = sess.run([self.valid_predictions,self.losses,self.updates],feed_dict=feed_dict)\n",
    "        return valid_predictions,loss\n",
    "    \n",
    "    def inference(self,sess,encode_input,encode_len):\n",
    "        feed_dict = {}\n",
    "        feed_dict[self.source_tokens] = encode_input\n",
    "        feed_dict[self.source_length] = encode_len\n",
    "        if self.beam_search:\n",
    "            predictions,probs,ids = sess.run([self.beam_predictions,self.beam_prob,self.beam_ids],feed_dict=feed_dict)\n",
    "            return predictions,ids\n",
    "        else:\n",
    "            predictions = sess.run([self.predictions],feed_dict=feed_dict)\n",
    "            return predictions\n",
    "    \n",
    "    def save_model(self,sess,checkpoint_dir):\n",
    "        writer = tf.summary.FileWriter(checkpoint_dir, sess.graph)\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "        saver.save(sess,checkpoint_dir + \"model.ckpt\",global_step=self.global_step)\n",
    "        \n",
    "    def restore_model(self,sess,checkpoint_dir):\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "        saver.restore(sess,tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(AttentionWrapperState(cell_state=<tf.Tensor 'S2S/bi_convert/BiasAdd/Identity:0' shape=(?, 128) dtype=float32>, attention=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros_2/Identity:0' shape=(?, 30) dtype=float32>, time=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros_1:0' shape=() dtype=int32>, alignments=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros/Identity:0' shape=(?, ?) dtype=float32>, alignment_history=(), attention_state=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros_3/Identity:0' shape=(?, ?) dtype=float32>), <tf.Tensor 'S2S/bi_convert/BiasAdd:0' shape=(?, 128) dtype=float32>)\n",
      "(AttentionWrapperState(cell_state=<tf.Tensor 'S2S/bi_convert/BiasAdd/Identity:0' shape=(?, 128) dtype=float32>, attention=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros_2/Identity:0' shape=(?, 30) dtype=float32>, time=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros_1:0' shape=() dtype=int32>, alignments=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros/Identity:0' shape=(?, ?) dtype=float32>, alignment_history=(), attention_state=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros_3/Identity:0' shape=(?, ?) dtype=float32>), <tf.Tensor 'S2S/bi_convert/BiasAdd:0' shape=(?, 128) dtype=float32>)\n",
      "beam\n",
      "(AttentionWrapperState(cell_state=<tf.Tensor 'S2S/tile_batch_2/Reshape:0' shape=(6, 128) dtype=float32>, attention=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros_2:0' shape=(6, 30) dtype=float32>, time=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros_1:0' shape=() dtype=int32>, alignments=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros:0' shape=(6, 10) dtype=float32>, alignment_history=(), attention_state=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros_3:0' shape=(6, 10) dtype=float32>), <tf.Tensor 'S2S/tile_batch_2/Reshape:0' shape=(6, 128) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "model = BasicS2SModel(vocab=vocab,mode=\"train\")\n",
    "\n",
    "tf.reset_default_graph()\n",
    "model = BasicS2SModel(vocab=vocab,mode=\"inference\")\n",
    "\n",
    "print(\"beam\")\n",
    "tf.reset_default_graph()\n",
    "model = BasicS2SModel(vocab=vocab,mode=\"inference\",use_beam_search=True,beam_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(AttentionWrapperState(cell_state=<tf.Tensor 'S2S/bi_convert/BiasAdd/Identity:0' shape=(?, 128) dtype=float32>, attention=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros_2/Identity:0' shape=(?, 30) dtype=float32>, time=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros_1:0' shape=() dtype=int32>, alignments=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros/Identity:0' shape=(?, ?) dtype=float32>, alignment_history=(), attention_state=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros_3/Identity:0' shape=(?, ?) dtype=float32>), <tf.Tensor 'S2S/bi_convert/BiasAdd:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'S2S/bi_convert/BiasAdd:0' shape=(?, 128) dtype=float32>)\n",
      "start to run\n",
      "('Epoch', 0)\n",
      "('epoch loss: ', 15.45228362083435)\n",
      "('Input:', 'What do you want to drink?')\n",
      "('Prediction:', '_GO_ _GO_ _GO_ .')\n",
      "('Target:', 'Beer please!')\n",
      "('Input:', 'What is your favorite beer?')\n",
      "('Prediction:', 'please _GO_ _GO_ Jaemin')\n",
      "('Target:', 'Leffe brown!')\n",
      "('Epoch', 20)\n",
      "('epoch loss: ', 3.1327723264694214)\n",
      "('Input:', 'What do you want to drink?')\n",
      "('Prediction:', '_GO_ Beer please !')\n",
      "('Target:', 'Beer please!')\n",
      "('Input:', 'What is your favorite beer?')\n",
      "('Prediction:', '_GO_ Leffe brown !')\n",
      "('Target:', 'Leffe brown!')\n",
      "('Epoch', 40)\n",
      "('epoch loss: ', 1.3934614434838295)\n",
      "('Input:', 'What do you want to drink?')\n",
      "('Prediction:', '_GO_ Beer please !')\n",
      "('Target:', 'Beer please!')\n",
      "('Input:', 'What is your favorite beer?')\n",
      "('Prediction:', '_GO_ Leffe ! !')\n",
      "('Target:', 'Leffe brown!')\n",
      "('Epoch', 60)\n",
      "('epoch loss: ', 0.5793319493532181)\n",
      "('Input:', 'What do you want to drink?')\n",
      "('Prediction:', '_GO_ Beer please !')\n",
      "('Target:', 'Beer please!')\n",
      "('Input:', 'What is your favorite beer?')\n",
      "('Prediction:', '_GO_ Leffe brown !')\n",
      "('Target:', 'Leffe brown!')\n",
      "('Epoch', 80)\n",
      "('epoch loss: ', 0.33209916204214096)\n",
      "('Input:', 'What do you want to drink?')\n",
      "('Prediction:', '_GO_ Beer please !')\n",
      "('Target:', 'Beer please!')\n",
      "('Input:', 'What is your favorite beer?')\n",
      "('Prediction:', '_GO_ Leffe brown !')\n",
      "('Target:', 'Leffe brown!')\n",
      "('Epoch', 100)\n",
      "('epoch loss: ', 0.11820418643765152)\n",
      "('Input:', 'What do you want to drink?')\n",
      "('Prediction:', '_GO_ Beer please !')\n",
      "('Target:', 'Beer please!')\n",
      "('Input:', 'What is your favorite beer?')\n",
      "('Prediction:', '_GO_ Leffe brown !')\n",
      "('Target:', 'Leffe brown!')\n",
      "('Epoch', 120)\n",
      "('epoch loss: ', 0.05124841572251171)\n",
      "('Input:', 'What do you want to drink?')\n",
      "('Prediction:', '_GO_ Beer please !')\n",
      "('Target:', 'Beer please!')\n",
      "('Input:', 'What is your favorite beer?')\n",
      "('Prediction:', '_GO_ Leffe brown !')\n",
      "('Target:', 'Leffe brown!')\n",
      "('Epoch', 140)\n",
      "('epoch loss: ', 0.04408168303780258)\n",
      "('Input:', 'What do you want to drink?')\n",
      "('Prediction:', '_GO_ Beer please !')\n",
      "('Target:', 'Beer please!')\n",
      "('Input:', 'What is your favorite beer?')\n",
      "('Prediction:', '_GO_ Leffe brown !')\n",
      "('Target:', 'Leffe brown!')\n",
      "('Epoch', 160)\n",
      "('epoch loss: ', 0.027643963578157127)\n",
      "('Input:', 'What do you want to drink?')\n",
      "('Prediction:', '_GO_ Beer please !')\n",
      "('Target:', 'Beer please!')\n",
      "('Input:', 'What is your favorite beer?')\n",
      "('Prediction:', '_GO_ Leffe brown !')\n",
      "('Target:', 'Leffe brown!')\n",
      "('Epoch', 180)\n",
      "('epoch loss: ', 0.020492725307121873)\n",
      "('Input:', 'What do you want to drink?')\n",
      "('Prediction:', '_GO_ Beer please !')\n",
      "('Target:', 'Beer please!')\n",
      "('Input:', 'What is your favorite beer?')\n",
      "('Prediction:', '_GO_ Leffe brown !')\n",
      "('Target:', 'Leffe brown!')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "loss_tracks = dict()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    model = BasicS2SModel(vocab=vocab,num_layers=3)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"start to run\")\n",
    "    loss_history = []\n",
    "    t0 = time.time()\n",
    "    for epoch in range(100):\n",
    "        all_preds = []\n",
    "        epoch_loss = 0\n",
    "        for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "            input_batch_tokens = []\n",
    "            target_batch_tokens = []\n",
    "            enc_sentence_lengths = []\n",
    "            dec_sentence_lengths = []\n",
    "\n",
    "            for input_sent in input_batch:\n",
    "                tokens, sent_len = sent2idx(input_sent)\n",
    "                input_batch_tokens.append(tokens)\n",
    "                enc_sentence_lengths.append(sent_len)\n",
    "\n",
    "            for target_sent in target_batch:\n",
    "                tokens, sent_len = sent2idx(target_sent,\n",
    "                             vocab=vocab,\n",
    "                             max_sentence_length=dec_sentence_length,\n",
    "                             is_target=True)\n",
    "                target_batch_tokens.append(tokens)\n",
    "                dec_sentence_lengths.append(sent_len)\n",
    "            batch_preds, batch_loss = model.train_one_step(sess,input_batch_tokens,enc_sentence_lengths,target_batch_tokens,dec_sentence_lengths)\n",
    "            epoch_loss += batch_loss\n",
    "            #loss_history.append(batch_loss)\n",
    "            all_preds.append(batch_preds)\n",
    "        loss_history.append(epoch_loss)\n",
    "        if epoch % 20 == 0:\n",
    "            print('Epoch', epoch)\n",
    "            print('epoch loss: ', epoch_loss )\n",
    "            for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "                print('Input:', input_sent)\n",
    "                print('Prediction:', idx2sent(pred, reverse_vocab=reverse_vocab))\n",
    "                print('Target:', target_sent)\n",
    "    \n",
    "    writer = tf.summary.FileWriter('/tmp/test_s2s/', sess.graph)\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    saver.save(sess,\"/tmp/test_s2s/model.ckpt\",global_step=model.global_step)\n",
    "\n",
    "    loss_took = time.time() - t0\n",
    "    s2s_track = pd.Series(loss_history, name='seq2seq')\n",
    "    tracks_batch = pd.DataFrame(dict(seq2seq=s2s_track))\n",
    "    tracks_batch.index.name = 'seq2seq'\n",
    "    s2s_track.index = s2s_track.index / loss_took\n",
    "    tracks_time = pd.DataFrame(dict(seq2seq=s2s_track)).ffill()\n",
    "    tracks_time.index.name = 'time (seconds)'\n",
    "    tracks_batch.plot(figsize=(8, 5), title='seq2seq, batch-time')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.486562252044678, 15.123505592346191, 14.678908586502075, 13.772567987442017, 12.345755100250244, 10.97653603553772, 10.495442867279053, 9.550214767456055, 8.946672558784485, 8.419196963310242, 7.716691374778748, 7.2025076150894165, 6.599082708358765, 6.114375174045563, 5.523699223995209, 5.382454574108124, 4.995788037776947, 4.3417728543281555, 4.113262444734573, 4.027514338493347, 3.7346969544887543, 3.2995285391807556, 3.5986821055412292, 3.112831473350525, 2.938249886035919, 2.6047632843255997, 2.32041996717453, 2.1969920694828033, 2.1852485835552216, 2.0100411027669907, 2.407414436340332, 1.6765832006931305, 1.9437263160943985, 2.166881948709488, 1.8001075685024261, 1.5403891950845718, 1.974030241370201, 1.2697069346904755, 1.2554083466529846, 1.3617087751626968, 1.267273798584938, 1.163369357585907, 1.1158602386713028, 1.0883061066269875, 0.9849008452147245, 0.8753483239561319, 1.1134662628173828, 1.056170329451561, 1.0251830257475376, 1.1948361806571484, 0.8479281365871429, 0.7339106015861034, 0.7954623866826296, 0.6466511338949203, 0.7639045864343643, 0.5945934904739261, 0.7006820961833, 0.6580221001058817, 0.518179215490818, 0.45501061901450157, 0.39597062207758427, 0.635470449924469, 0.6092827534303069, 0.45295005571097136, 0.6489468044601381, 0.4142683185636997, 0.48538088984787464, 0.42852817848324776, 0.4075015550479293, 0.3696431568823755, 0.3814865108579397, 0.4356080209836364, 0.280423522926867, 0.4912167424336076, 0.27201703004539013, 0.5574890729039907, 0.4886102396994829, 0.4488453222438693, 0.40625421330332756, 0.29563996428623796, 0.33447437500581145, 0.2913865917362273, 0.31374336034059525, 0.374893925152719, 0.2606971636414528, 0.2920053778216243, 0.4381555994041264, 0.25999026373028755, 0.37624105997383595, 0.16401101183146238, 0.2212003357708454, 0.18159007746726274, 0.1601698063313961, 0.16300117131322622, 0.1438083746470511, 0.14109755936078727, 0.16325491573661566, 0.12328473012894392, 0.14746328443288803, 0.20236490666866302]\n"
     ]
    }
   ],
   "source": [
    "print (loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Gready search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(AttentionWrapperState(cell_state=<tf.Tensor 'S2S/bi_convert/BiasAdd/Identity:0' shape=(?, 128) dtype=float32>, attention=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros_2/Identity:0' shape=(?, 30) dtype=float32>, time=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros_1:0' shape=() dtype=int32>, alignments=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros/Identity:0' shape=(?, ?) dtype=float32>, alignment_history=(), attention_state=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros_3/Identity:0' shape=(?, ?) dtype=float32>), <tf.Tensor 'S2S/bi_convert/BiasAdd:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'S2S/bi_convert/BiasAdd:0' shape=(?, 128) dtype=float32>)\n",
      "INFO:tensorflow:Restoring parameters from /tmp/test_s2s/model.ckpt-400\n",
      "('Input:', 'Which programming language do you use?')\n",
      "[ 0 12 38 30  3  3  3  3  3  3]\n",
      "('Prediction:', '_GO_ I like Python . . . . . .')\n",
      "('Target:', 'I like Python.')\n",
      "('Input:', 'See you later.')\n",
      "[ 0 13 13  3  3  3  3  3  3  3]\n",
      "('Prediction:', '_GO_ Bye Bye . . . . . . .')\n",
      "('Target:', 'Bye Bye.')\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    model = BasicS2SModel(vocab=vocab,mode=\"inference\",use_beam_search=False,num_layers=3)\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    saver.restore(sess,tf.train.latest_checkpoint('/tmp/test_s2s/'))\n",
    "    batch_preds = []\n",
    "    batch_tokens = []\n",
    "    batch_sent_lens = []\n",
    "\n",
    "    for input_sent in input_batches[1]:\n",
    "        tokens, sent_len = sent2idx(input_sent)\n",
    "        batch_tokens.append(tokens)\n",
    "        batch_sent_lens.append(sent_len)\n",
    "\n",
    "    batch_preds = model.inference(sess,batch_tokens,batch_sent_lens)\n",
    "\n",
    "    for input_sent, target_sent, pred in zip(input_batches[1], target_batches[1], batch_preds[0]):\n",
    "        print('Input:', input_sent)\n",
    "        print(pred)\n",
    "        print('Prediction:', idx2sent(pred, reverse_vocab=reverse_vocab))\n",
    "        print('Target:', target_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Beam search\n",
    "\n",
    "> Beam search results are not good, need to take a deep look into the implementation, suggested not to use it right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(AttentionWrapperState(cell_state=<tf.Tensor 'S2S/tile_batch_2/Reshape:0' shape=(6, 128) dtype=float32>, attention=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros_2:0' shape=(6, 30) dtype=float32>, time=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros_1:0' shape=() dtype=int32>, alignments=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros:0' shape=(6, 10) dtype=float32>, alignment_history=(), attention_state=<tf.Tensor 'S2S/AttentionWrapperZeroState/zeros_3:0' shape=(6, 10) dtype=float32>), <tf.Tensor 'S2S/tile_batch_2/Reshape:0' shape=(6, 128) dtype=float32>, <tf.Tensor 'S2S/tile_batch_2/Reshape:0' shape=(6, 128) dtype=float32>)\n",
      "INFO:tensorflow:Restoring parameters from /tmp/test_s2s/model.ckpt-400\n",
      "('Input:', 'What do you want to drink?')\n",
      "('Prediction:', '_GO_ Beer please ! ! ! ! ! . .')\n",
      "('Prediction:', '_GO_ Beer please ! ! ! ! ! ! .')\n",
      "('Prediction:', '_GO_ Beer please ! ! ! ! . . .')\n",
      "('Target:', 'Beer please!')\n",
      "('Input:', 'What is your favorite beer?')\n",
      "('Prediction:', '_GO_ Leffe brown ! ! ! . . . .')\n",
      "('Prediction:', '_GO_ Leffe brown ! ! ! ! . . .')\n",
      "('Prediction:', '_GO_ Leffe brown ! ! . . . . .')\n",
      "('Target:', 'Leffe brown!')\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    model = BasicS2SModel(vocab=vocab,mode=\"inference\",use_beam_search=True,beam_size=3,num_layers=3)\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    saver.restore(sess,tf.train.latest_checkpoint('/tmp/test_s2s/'))\n",
    "    batch_preds = []\n",
    "    batch_tokens = []\n",
    "    batch_sent_lens = []\n",
    "\n",
    "    for input_sent in input_batches[3]:\n",
    "        tokens, sent_len = sent2idx(input_sent)\n",
    "        batch_tokens.append(tokens)\n",
    "        batch_sent_lens.append(sent_len)\n",
    "    batch_preds,ids = model.inference(sess,batch_tokens,batch_sent_lens)\n",
    "    for input_sent, target_sent, pred in zip(input_batches[3], target_batches[3], batch_preds):\n",
    "        print('Input:', input_sent)\n",
    "        for p in pred:\n",
    "            print('Prediction:', idx2sent(p, reverse_vocab=reverse_vocab))\n",
    "        print('Target:', target_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
